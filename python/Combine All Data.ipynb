{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "from umap import UMAP\n",
    "from scipy.ndimage import maximum_filter, gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from utils.list_files import list_files, get_stem\n",
    "from utils.histogram_equalize import histogram_equalize\n",
    "from utils.ffmpeg import auread\n",
    "from utils.imutil import imshow, imresize\n",
    "\n",
    "from siren import build_fingerprint, build_features, build_targets, to_indices\n",
    "\n",
    "sr = 44100\n",
    "hop_length = 512\n",
    "feature_framerate = sr / hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = {}\n",
    "\n",
    "for audio_fn in list_files('data', 'wav'):\n",
    "    stem = get_stem(audio_fn)\n",
    "    print('analyzing', stem)\n",
    "    \n",
    "    y,sr = auread(audio_fn, mono=True)\n",
    "    amp = build_fingerprint(y, sr)\n",
    "    features = build_features(y, sr)\n",
    "    rms = features['rms'].flatten()\n",
    "    centroid = features['centroid'].flatten()\n",
    "    flatness = features['flatness'].flatten()\n",
    "    \n",
    "#     amp = grouped[stem]['amp']\n",
    "#     rms = grouped[stem]['rms']\n",
    "#     centroid = grouped[stem]['centroid']\n",
    "#     flatness = grouped[stem]['flatness']\n",
    "    \n",
    "    n = len(amp)\n",
    "    stems = [stem] * n\n",
    "    \n",
    "    grouped[stem] = {\n",
    "        'stems': stems,\n",
    "        'amp': amp,\n",
    "        'rms': rms,\n",
    "        'centroid': centroid,\n",
    "        'flatness': flatness\n",
    "    }\n",
    "    \n",
    "    annotation_fn = f'data/{stem}.Table.1.selections.txt'\n",
    "    if os.path.exists(annotation_fn):\n",
    "        print('loading annotation')\n",
    "        units, singing, themes, unit_positions = build_targets(annotation_fn, y, sr, amp)\n",
    "    else:\n",
    "        print('empty annotation')\n",
    "        units = np.asarray([''] * n, '<U8')\n",
    "        singing = -np.ones(n, np.int8)\n",
    "        themes = -np.ones(n, np.int8)\n",
    "        unit_positions = np.zeros(n, np.float32)\n",
    "        \n",
    "    grouped[stem].update({\n",
    "        'units': units,\n",
    "        'singing': singing,\n",
    "        'themes': themes,\n",
    "        'unit_positions': unit_positions\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create derived data\n",
    "for stem, group in grouped.items():\n",
    "    n = len(group['amp'])\n",
    "    annotated = np.any(group['units'] != '')\n",
    "    group['annotated'] = np.asarray([annotated] * n)\n",
    "    \n",
    "    # take 5 second max filter on rms for fast signal\n",
    "    rms = group['rms']\n",
    "    group['local_rms'] = rms / maximum_filter(rms, size=feature_framerate*5)\n",
    "    \n",
    "    # 2 second lowpass rms for slow signal\n",
    "    lowpass_rms = gaussian_filter1d(rms, sigma=feature_framerate*0.5)\n",
    "    lowpass_rms /= maximum_filter(lowpass_rms, size=feature_framerate*15)\n",
    "    group['lowpass_rms'] = lowpass_rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these can be used to save and restore state between sessions, to save analysis time\n",
    "\n",
    "def dump_cache(e, name):\n",
    "    with open(f'cache/{name}.pkl', 'wb') as f:\n",
    "        return pickle.dump(e, f)\n",
    "    \n",
    "def load_cache(name):\n",
    "    with open(f'cache/{name}.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "dump_cache(grouped, 'grouped')\n",
    "# grouped = load_cache('grouped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ungroup into list of lists\n",
    "ungrouped = defaultdict(list)\n",
    "for stem, group in grouped.items():\n",
    "    for k,v in group.items():\n",
    "        ungrouped[k].append(v)\n",
    "        \n",
    "def stack(arr):\n",
    "    # hstack 1 dimensional\n",
    "    if len(np.shape(arr[0])) == 1:\n",
    "        return np.hstack(arr)\n",
    "    # vstack two+ dimensional\n",
    "    return np.vstack(arr)\n",
    "\n",
    "# stack and convert to flat arrays\n",
    "ungrouped = {k:stack(v) for k,v in ungrouped.items()}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserves \"unknown\" categories as -1\n",
    "def to_indices(arr, unknown=''):\n",
    "    unique = np.unique(arr)\n",
    "    if unknown in unique:\n",
    "        unique = [e for e in unique if e != unknown]\n",
    "    mapping = {e:i for i,e in enumerate(unique)}\n",
    "    mapping[unknown] = -1\n",
    "    mapped = [mapping[e] for e in arr]\n",
    "    return np.asarray(mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_indices = to_indices(ungrouped['units'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "unique_unit_indices = np.unique(unit_indices)\n",
    "embed_amp_per_unit_2d = np.zeros((len(unit_indices), 2))\n",
    "embed_amp_per_unit_1d = np.zeros((len(unit_indices), 1))\n",
    "\n",
    "for unit_index in unique_unit_indices:\n",
    "    if unit_index == -1:\n",
    "        print('skipping unlabeled')\n",
    "        continue\n",
    "    print(unit_index)\n",
    "    valid, = np.where(unit_indices == unit_index)\n",
    "    amp_sub = ungrouped['amp'][valid]\n",
    "    embed_amp_sub_per_unit_2d = UMAP(n_components=2).fit_transform(amp_sub)\n",
    "    embed_amp_sub_per_unit_1d = UMAP(n_components=1).fit_transform(amp_sub)\n",
    "    embed_amp_per_unit_2d[valid] = histogram_equalize(embed_amp_sub_per_unit_2d, max_val=1.0, endpoint=True)\n",
    "    embed_amp_per_unit_1d[valid] = histogram_equalize(embed_amp_sub_per_unit_1d, max_val=1.0, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# handle the unlabeled data using supervision\n",
    "embed_amp_unit_2d = UMAP(n_components=2).fit_transform(ungrouped['amp'], unit_indices)\n",
    "embed_amp_unit_1d = UMAP(n_components=1).fit_transform(ungrouped['amp'], unit_indices)\n",
    "\n",
    "empty_indices = unit_indices == -1\n",
    "embed_amp_per_unit_2d[empty_indices] = embed_amp_unit_2d[empty_indices]\n",
    "embed_amp_per_unit_1d[empty_indices] = embed_amp_unit_1d[empty_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lab2rgb(brightness, ab):\n",
    "    lab_colors = (ab * 200) - 100\n",
    "    lab_colors = np.hstack((brightness * np.ones((len(lab_colors),1)), lab_colors))\n",
    "    rgb_colors = cv2.cvtColor(lab_colors.reshape(-1,1,3).astype(np.float32), cv2.COLOR_Lab2RGB)\n",
    "    return rgb_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put back in groups using stem for lookup\n",
    "for stem, group in grouped.items():    \n",
    "    indices = ungrouped['stems'] == stem\n",
    "#     group['embed_amp_theme'] = embed_amp_theme[indices]\n",
    "#     group['embed_amp_unit'] = embed_amp_unit[indices]\n",
    "#     group['unit_indices'] = unit_indices[indices]\n",
    "    group['embed_amp_per_unit_1d'] = embed_amp_per_unit_1d[indices]\n",
    "    group['embed_amp_per_unit_2d'] = embed_amp_per_unit_2d[indices]\n",
    "        \n",
    "dump_cache(grouped, 'grouped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_and_equalize(x, sigma):\n",
    "    blurred = gaussian_filter1d(x, sigma, axis=0).T\n",
    "    for i in range(len(blurred)):\n",
    "        blurred[i] = histogram_equalize(blurred[i], max_val=1, endpoint=True)\n",
    "    return blurred.T\n",
    "\n",
    "for stem, group in grouped.items():\n",
    "    sigma = feature_framerate * 0.1\n",
    "    group['embed_amp_per_unit_1d_lowpass'] = blur_and_equalize(group['embed_amp_per_unit_1d'], sigma)\n",
    "    group['embed_amp_per_unit_2d_lowpass'] = blur_and_equalize(group['embed_amp_per_unit_2d'], sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linmap(x, xmin, xmax, outmin, outmax):\n",
    "    return outmin + (outmax - outmin) * (x - xmin) / (xmax - xmin)\n",
    "\n",
    "def linear_window(x, edge):\n",
    "    y = np.minimum(1, linmap(x, 0, edge, 0, 1))\n",
    "    y = np.minimum(y, linmap(x, 1-edge, 1, 1, 0))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 6\n",
    "n_lights = 15\n",
    "global_lights = 3\n",
    "local_lights = n_lights - global_lights\n",
    "positions = np.linspace(0, 1, local_lights)\n",
    "\n",
    "def gaussian(x,x0,sigma):\n",
    "    return np.exp(-np.power((x - x0)/sigma, 2.)/2.)\n",
    "\n",
    "def get_lighting(e):\n",
    "    ab = None\n",
    "    center = None\n",
    "    rms = None\n",
    "    \n",
    "    colors = np.zeros((n_lights, channels))\n",
    "    \n",
    "    if e['annotated']:\n",
    "        if e['units'] != '':\n",
    "            ab = e['embed_amp_per_unit_2d']\n",
    "            center = e['embed_amp_per_unit_1d']\n",
    "            rms = e['local_rms']\n",
    "    else:\n",
    "        ab = e['embed_amp_per_unit_2d_lowpass']\n",
    "        center = e['embed_amp_per_unit_1d_lowpass']\n",
    "        rms = e['local_rms']\n",
    "        \n",
    "    if ab is not None:\n",
    "        red, green, blue = lab2rgb(70, ab[np.newaxis,:]).flatten()\n",
    "        rgbawu = np.array([red, green, blue, red, blue, green])\n",
    "        weights = gaussian(positions, center, 0.3)[:,np.newaxis]\n",
    "        colors[-local_lights:] = weights * rgbawu\n",
    "        colors *= rms\n",
    "        \n",
    "        unit_position = e['unit_positions']\n",
    "        if unit_position > 0:\n",
    "            colors *= linear_window(unit_position, 0.05)\n",
    "\n",
    "    colors[:global_lights] = colors[-local_lights:].max(axis=0)\n",
    "\n",
    "    return colors\n",
    "    \n",
    "\n",
    "for stem, group in grouped.items():\n",
    "    print(stem)\n",
    "    keys = group.keys()\n",
    "    design = []\n",
    "    for e in zip(*group.values()):\n",
    "        elt = dict(zip(keys, e))\n",
    "        design.append(get_lighting(elt))\n",
    "    design = np.asarray(design)\n",
    "    design = np.clip(design, 0, 1)\n",
    "\n",
    "    np.save(f'design/{stem}.npy', design)\n",
    "    \n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
